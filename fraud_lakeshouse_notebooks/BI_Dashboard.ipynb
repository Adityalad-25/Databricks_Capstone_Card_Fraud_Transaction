{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9eeaef3b-be92-4909-ac1e-c28e14b76808",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import sum, count, avg, col\n",
    "\n",
    "fact_df  = spark.read.table(\"fraud_lakehouse.gold.fact_transactions\")\n",
    "dim_merch = spark.read.table(\"fraud_lakehouse.gold.dim_merchants\")\n",
    "dim_cust  = spark.read.table(\"fraud_lakehouse.gold.dim_customer\").filter(col(\"is_current\") == True)\n",
    "\n",
    "bi_daily_summary = (\n",
    "    fact_df.alias(\"f\")\n",
    "    .join(dim_merch.alias(\"m\"), col(\"f.merchant_fk\") == col(\"m.merchant_sk\"))\n",
    "    .join(dim_cust.alias(\"c\"),  col(\"f.customer_fk\") == col(\"c.customer_sk\"))\n",
    "    .groupBy(\n",
    "        col(\"f.date_key\"),\n",
    "        col(\"m.merchant_category\"),\n",
    "        col(\"c.risk_segment\"),\n",
    "        col(\"c.home_country\")\n",
    "    )\n",
    "    .agg(\n",
    "        sum(\"f.amount_usd\").alias(\"total_sales\"),\n",
    "        count(\"f.transaction_id\").alias(\"total_transactions\"),\n",
    "        sum(\"f.fraud_flag\").alias(\"fraud_count\"),\n",
    "        avg(\"f.amount_usd\").alias(\"avg_transaction_value\")\n",
    "    )\n",
    "    .withColumn(\"fraud_rate_percentage\", (col(\"fraud_count\") / col(\"total_transactions\")) * 100)\n",
    ")\n",
    "\n",
    "table_name = \"fraud_lakehouse.gold.bi_daily_sales_summary\"\n",
    "bi_daily_summary.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "print(f\"BI Table '{table_name}' created.\")\n",
    "display(spark.read.table(table_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "815fd960-9169-429b-95e9-4eac2c9f7d84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        merchant_category,\n",
    "        SUM(total_transactions) as txns,\n",
    "        SUM(fraud_count) as fraud_cases,\n",
    "        ROUND((SUM(fraud_count) / SUM(total_transactions)) * 100, 2) as fraud_rate_percent\n",
    "    FROM fraud_lakehouse.gold.bi_daily_sales_summary\n",
    "    GROUP BY merchant_category\n",
    "    ORDER BY fraud_rate_percent DESC\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab7a8f88-7338-46e1-bd29-763a6efb23ac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        risk_segment,\n",
    "        SUM(total_sales) as revenue,\n",
    "        SUM(fraud_count) as fraud_events\n",
    "    FROM fraud_lakehouse.gold.bi_daily_sales_summary\n",
    "    GROUP BY risk_segment\n",
    "    ORDER BY revenue DESC\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5860f0ee-79e2-47ba-9c98-7f858992a442",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import count, sum, avg, max, col\n",
    "\n",
    "fact = spark.read.table(\"fraud_lakehouse.gold.fact_transactions\")\n",
    "cust = spark.read.table(\"fraud_lakehouse.gold.dim_customer\").filter(col(\"is_current\") == True)\n",
    "customer_360 = (\n",
    "    fact.alias(\"f\")\n",
    "    .join(cust.alias(\"c\"), col(\"f.customer_fk\") == col(\"c.customer_sk\"))\n",
    "    .groupBy(\n",
    "        col(\"c.customer_id\"),\n",
    "        col(\"c.home_country\"),\n",
    "        col(\"c.risk_segment\")\n",
    "    )\n",
    "    .agg(\n",
    "        sum(\"f.amount_usd\").alias(\"lifetime_spend\"),\n",
    "        count(\"f.transaction_id\").alias(\"lifetime_transactions\"),\n",
    "        sum(\"f.fraud_flag\").alias(\"total_fraud_events\"),\n",
    "        avg(\"f.amount_usd\").alias(\"avg_spend_per_txn\"),\n",
    "        max(\"f.date_key\").alias(\"last_seen_date\")\n",
    "    )\n",
    ")\n",
    "customer_360.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"fraud_lakehouse.gold.customer_360_profile\")\n",
    "\n",
    "print(\"Customer 360 Table Created.\")\n",
    "display(spark.read.table(\"fraud_lakehouse.gold.customer_360_profile\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5a1209b-15c0-401a-b748-c81a70113cc5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        HOUR(transaction_ts) as hour_of_day,\n",
    "        COUNT(*) as total_txns,\n",
    "        SUM(fraud_flag) as fraud_cases,\n",
    "        ROUND((SUM(fraud_flag) / COUNT(*)) * 100, 2) as fraud_rate_percent\n",
    "    FROM fraud_lakehouse.gold.fact_transactions\n",
    "    GROUP BY hour_of_day\n",
    "    ORDER BY hour_of_day ASC\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "924f5fd9-3f4f-4607-b393-bba24d28a545",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        device_type,\n",
    "        SUM(amount_usd) as total_volume,\n",
    "        SUM(fraud_flag) as fraud_count,\n",
    "        ROUND((SUM(fraud_flag) / COUNT(*)) * 100, 2) as fraud_rate_percent\n",
    "    FROM fraud_lakehouse.gold.fact_transactions\n",
    "    GROUP BY device_type\n",
    "    ORDER BY fraud_rate_percent DESC\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42260b2e-70ff-41d2-8e85-7f89ec8a7269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        c.home_country as customer_country,\n",
    "        m.merchant_country as merchant_country,\n",
    "        COUNT(f.transaction_id) as total_txns,\n",
    "        SUM(f.fraud_flag) as fraud_cases\n",
    "    FROM fraud_lakehouse.gold.fact_transactions f\n",
    "    JOIN fraud_lakehouse.gold.dim_customer c ON f.customer_fk = c.customer_sk\n",
    "    JOIN fraud_lakehouse.gold.dim_merchants m ON f.merchant_fk = m.merchant_sk\n",
    "    WHERE c.home_country != m.merchant_country \n",
    "    GROUP BY c.home_country, m.merchant_country\n",
    "    HAVING fraud_cases > 0\n",
    "    ORDER BY fraud_cases DESC\n",
    "    LIMIT 10\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "49662495-bde9-446f-8d61-6b93851905a5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        CASE WHEN fraud_flag = 1 THEN 'Fraudulent' ELSE 'Legitimate' END as status,\n",
    "        COUNT(*) as count,\n",
    "        ROUND(AVG(amount_usd), 2) as avg_transaction_value,\n",
    "        ROUND(MAX(amount_usd), 2) as max_transaction_value\n",
    "    FROM fraud_lakehouse.gold.fact_transactions\n",
    "    GROUP BY fraud_flag\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34f00018-10de-4a39-a560-8c45a6745146",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        m.merchant_name,\n",
    "        m.merchant_category,\n",
    "        COUNT(f.transaction_id) as total_txns,\n",
    "        SUM(f.fraud_flag) as fraud_events,\n",
    "        ROUND((SUM(f.fraud_flag) / COUNT(f.transaction_id)) * 100, 2) as merchant_fraud_rate\n",
    "    FROM fraud_lakehouse.gold.fact_transactions f\n",
    "    JOIN fraud_lakehouse.gold.dim_merchants m ON f.merchant_fk = m.merchant_sk\n",
    "    GROUP BY m.merchant_name, m.merchant_category\n",
    "    HAVING total_txns > 5 \n",
    "    ORDER BY merchant_fraud_rate DESC\n",
    "    LIMIT 10\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "486f9310-dd1a-4d04-b5b7-d3f39b6e977d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT \n",
    "        card_type,\n",
    "        SUM(fraud_flag) as total_fraud_cases,\n",
    "        ROUND(SUM(amount_usd), 2) as total_fraud_value\n",
    "    FROM fraud_lakehouse.gold.fact_transactions\n",
    "    WHERE fraud_flag = 1\n",
    "    GROUP BY card_type\n",
    "    ORDER BY total_fraud_value DESC\n",
    "\"\"\").display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "84a57ebf-e6e5-4e24-9168-0668bc7a1854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql.functions import col, hour, when, concat_ws, lit, array, array_remove\n",
    "\n",
    "fact  = spark.read.table(\"fraud_lakehouse.gold.fact_transactions\")\n",
    "cust  = spark.read.table(\"fraud_lakehouse.gold.dim_customer\").filter(col(\"is_current\") == True)\n",
    "merch = spark.read.table(\"fraud_lakehouse.gold.dim_merchants\")\n",
    "\n",
    "\n",
    "joined_df = (\n",
    "    fact.alias(\"f\")\n",
    "    .join(cust.alias(\"c\"),  col(\"f.customer_fk\") == col(\"c.customer_sk\"))\n",
    "    .join(merch.alias(\"m\"), col(\"f.merchant_fk\") == col(\"m.merchant_sk\"))\n",
    ")\n",
    "\n",
    "\n",
    "rule_night_owl = (\n",
    "    (hour(col(\"f.transaction_ts\")).between(2, 4)) & \n",
    "    (col(\"f.amount\") > 1000)\n",
    ")\n",
    "\n",
    "rule_cross_border = (\n",
    "    col(\"c.home_country\") != col(\"m.merchant_country\")\n",
    ")\n",
    "\n",
    "\n",
    "rule_high_value = (\n",
    "    col(\"f.amount\") > 3000\n",
    ")\n",
    "\n",
    "\n",
    "flagged_df = (\n",
    "    joined_df\n",
    "    .withColumn(\"rule_night_owl\", when(rule_night_owl, \"Night_Owl_>1k\").otherwise(lit(None)))\n",
    "    .withColumn(\"rule_cross_border\", when(rule_cross_border, \"Cross_Border\").otherwise(lit(None)))\n",
    "    .withColumn(\"rule_high_value\", when(rule_high_value, \"High_Value_>3k\").otherwise(lit(None)))\n",
    "    \n",
    "    \n",
    "    .withColumn(\"suspicion_reasons\", \n",
    "        concat_ws(\", \", \n",
    "            col(\"rule_night_owl\"), \n",
    "            col(\"rule_cross_border\"), \n",
    "            col(\"rule_high_value\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    .filter(col(\"suspicion_reasons\") != \"\")\n",
    "    .select(\n",
    "        col(\"f.transaction_id\"),\n",
    "        col(\"f.transaction_ts\"),\n",
    "        col(\"f.amount\"),\n",
    "        col(\"c.customer_id\"),\n",
    "        col(\"c.home_country\"),\n",
    "        col(\"m.merchant_name\"),\n",
    "        col(\"m.merchant_country\"),\n",
    "        col(\"suspicion_reasons\"), \n",
    "        col(\"f.fraud_flag\") \n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "table_name = \"fraud_lakehouse.gold.suspicious_activity_report\"\n",
    "print(f\"Running Rule Engine... Saving to {table_name}\")\n",
    "\n",
    "flagged_df.write.format(\"delta\").mode(\"overwrite\").saveAsTable(table_name)\n",
    "\n",
    "print(\"Rule Engine Complete. Suspicious transactions tagged.\")\n",
    "display(spark.read.table(table_name).limit(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "15bde974-2b1b-48ad-90ff-4362033184c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "spark.sql(f\"\"\"\n",
    "    SELECT \n",
    "        suspicion_reasons,\n",
    "        COUNT(*) as flagged_count,\n",
    "        SUM(fraud_flag) as actual_fraud_found,\n",
    "        ROUND((SUM(fraud_flag) / COUNT(*)) * 100, 1) as precision_rate\n",
    "    FROM {table_name}\n",
    "    GROUP BY suspicion_reasons\n",
    "    ORDER BY actual_fraud_found DESC\n",
    "\"\"\").display()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BI_Dashboard",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
